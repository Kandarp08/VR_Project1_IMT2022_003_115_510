{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhaiJckA0WyP",
        "outputId": "3bb67efc-c7c1-4a64-a347-31c96f870703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted to: /content/extracted_files\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "zip_path = \"/content/dataset.zip\"\n",
        "extract_path = \"/content/extracted_files\"\n",
        "\n",
        "# Extract ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Extracted to: {extract_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIEZHmKl0WyO",
        "outputId": "9f4c9628-5210-41ba-849f-67b6661d5fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.2709\n",
            "Epoch [20/100], Loss: 0.1131\n",
            "Epoch [30/100], Loss: 0.0557\n",
            "Epoch [40/100], Loss: 0.0226\n",
            "Epoch [50/100], Loss: 0.0111\n",
            "Epoch [60/100], Loss: 0.0069\n",
            "Epoch [70/100], Loss: 0.0041\n",
            "Epoch [80/100], Loss: 0.0036\n",
            "Epoch [90/100], Loss: 0.0026\n",
            "Epoch [100/100], Loss: 0.0030\n",
            "\n",
            "SVM Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.93       386\n",
            "           1       0.93      0.95      0.94       433\n",
            "\n",
            "    accuracy                           0.94       819\n",
            "   macro avg       0.94      0.94      0.94       819\n",
            "weighted avg       0.94      0.94      0.94       819\n",
            "\n",
            "SVM Accuracy: 0.938949938949939\n",
            "\n",
            "Random Forest Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.85      0.90       386\n",
            "           1       0.88      0.97      0.92       433\n",
            "\n",
            "    accuracy                           0.91       819\n",
            "   macro avg       0.92      0.91      0.91       819\n",
            "weighted avg       0.92      0.91      0.91       819\n",
            "\n",
            "Random Forest Accuracy: 0.9133089133089133\n",
            "\n",
            "Neural Network Classifier Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.93       386\n",
            "           1       0.93      0.94      0.94       433\n",
            "\n",
            "    accuracy                           0.93       819\n",
            "   macro avg       0.93      0.93      0.93       819\n",
            "weighted avg       0.93      0.93      0.93       819\n",
            "\n",
            "Neural Network Accuracy: 0.9328449328449329\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from skimage.feature import hog, local_binary_pattern\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "mask_path = \"/content/extracted_files/dataset/with_mask\"\n",
        "no_mask_path = \"/content/extracted_files/dataset/without_mask\"\n",
        "\n",
        "IMG_SIZE = (64, 64)\n",
        "\n",
        "# Function to extract HOG features\n",
        "def extract_hog_features(image):\n",
        "    image = cv2.resize(image, IMG_SIZE)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    fd, _ = hog(gray, pixels_per_cell=(8, 8), cells_per_block=(2, 2), orientations=9, visualize=True)\n",
        "    return fd\n",
        "\n",
        "# Function to extract LBP features\n",
        "def extract_lbp_features(image):\n",
        "    image = cv2.resize(image, IMG_SIZE)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    lbp = local_binary_pattern(gray, P=8, R=1, method=\"uniform\")\n",
        "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)\n",
        "    return hist\n",
        "\n",
        "def load_dataset():\n",
        "    X, y = [], []\n",
        "\n",
        "    for img_name in os.listdir(mask_path):\n",
        "        img = cv2.imread(os.path.join(mask_path, img_name))\n",
        "        if img is not None:\n",
        "            hog_features = extract_hog_features(img)\n",
        "            lbp_features = extract_lbp_features(img)\n",
        "            combined_features = np.hstack((hog_features, lbp_features))\n",
        "            X.append(combined_features)\n",
        "            y.append(1)\n",
        "\n",
        "    for img_name in os.listdir(no_mask_path):\n",
        "        img = cv2.imread(os.path.join(no_mask_path, img_name))\n",
        "        if img is not None:\n",
        "            hog_features = extract_hog_features(img)\n",
        "            lbp_features = extract_lbp_features(img)\n",
        "            combined_features = np.hstack((hog_features, lbp_features))\n",
        "            X.append(combined_features)\n",
        "            y.append(0)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Preprocessing the dataset\n",
        "X, y = load_dataset()\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# SVM Classifier\n",
        "svm_model = SVC(kernel='rbf', C=10, gamma='scale')\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_preds = svm_model.predict(X_test)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=5, class_weight='balanced', random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_preds = rf_model.predict(X_test)\n",
        "\n",
        "# Neural Network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = SimpleNN(input_dim)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network with learning rate scheduling\n",
        "num_epochs = 100\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluate the neural network\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    nn_preds = model(X_test_tensor)\n",
        "    nn_preds = (nn_preds >= 0.5).float().numpy().flatten()\n",
        "\n",
        "# Results\n",
        "print(\"\\nSVM Classifier Report:\")\n",
        "print(classification_report(y_test, svm_preds))\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_preds))\n",
        "\n",
        "print(\"\\nRandom Forest Classifier Report:\")\n",
        "print(classification_report(y_test, rf_preds))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_preds))\n",
        "\n",
        "print(\"\\nNeural Network Classifier Report:\")\n",
        "print(classification_report(y_test, nn_preds))\n",
        "print(\"Neural Network Accuracy:\", accuracy_score(y_test, nn_preds))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uP3B_8Rq1Mbq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}